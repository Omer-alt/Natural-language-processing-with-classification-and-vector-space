{"cells":[{"cell_type":"markdown","metadata":{"id":"thobkiOZ76P9"},"source":["\n","<h1 style=\"font-family:verdana;font-size:300%;text-align:center;background-color:#f2f2f2;color:#0d0d0d\">AMMI_2024_NLP - Week 1</h1>\n","\n","<h1 style=\"font-family:verdana;font-size:180%;text-align:Center;color:#993333\"> Lab 3: N-gram models </h1>\n","\n","\n","Before we start, please change the name of the notebook to the following format : **Firstname_LASTNAME_Lab3__N_gram_models.ipynb**\n","\n","\n","In some cells and files you will see code blocks that look like this:\n","\n","```python\n","##############################################################################\n","#                    TODO: Write the equation for a line                     #\n","##############################################################################\n","pass\n","##############################################################################\n","#                              END OF YOUR CODE                              #\n","##############################################################################\n","```\n","\n","You should replace the `pass` statement with your own code and leave the blocks intact, like this:\n","\n","```python\n","##############################################################################\n","#                    TODO: Write the equation for a line                     #\n","##############################################################################\n","y = m * x + b\n","##############################################################################\n","#                              END OF YOUR CODE                              #\n","##############################################################################\n","```"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"AO2Q6hrQ76QC","executionInfo":{"status":"ok","timestamp":1719773500247,"user_tz":0,"elapsed":349,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["import io, sys, math, re\n","from collections import defaultdict\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NywuM_YBXKOq","outputId":"73b61389-bdff-4829-a332-b2413d0284e7","executionInfo":{"status":"ok","timestamp":1719773503156,"user_tz":0,"elapsed":2569,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":17,"metadata":{"id":"wG9pqSoV76QD","executionInfo":{"status":"ok","timestamp":1719773503156,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["# data_loader\n","def load_data(filename):\n","    '''\n","    parameters:\n","    filename (string): datafile\n","\n","    Returns:\n","    data (list of lists): each list is a sentence of the text\n","    vocab (dictionary): {word: no of times it appears in the text}\n","    '''\n","    fin = io.open(filename, 'r', encoding='utf-8')\n","    data = []\n","    vocab = defaultdict(lambda:0)\n","    for line in fin:\n","        sentence = line.split()\n","        data.append(sentence)\n","        for word in sentence:\n","            vocab[word] += 1\n","    return data, vocab"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"amQ02wsD76QE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a4a87a25-91ae-4ce3-c6a0-2cb51a722c28","executionInfo":{"status":"ok","timestamp":1719773503156,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["load training set..\n","\n","\n","['<s>', 'my', 'fathers', \"don't\", 'speak', 'dutch.', '</s>']\n","\n","\n","how : 107\n","load validation set\n"]}],"source":["\n","print(\"load training set..\")\n","print(\"\\n\")\n","train_data, vocab = load_data(\"drive/MyDrive/NLP_Week1_PS/Lab3/train1.txt\")\n","print(train_data[0])\n","print(\"\\n\")\n","print(\"how :\",vocab['how'])\n","print(\"load validation set\")\n","valid_data, _ = load_data(\"drive/MyDrive/NLP_Week1_PS/Lab3/valid1.txt\")\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"6kfh1SAS76QE","executionInfo":{"status":"ok","timestamp":1719773503156,"user_tz":0,"elapsed":1,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def remove_rare_words(data, vocab, mincount = 1):\n","    '''\n","    Parameters:\n","    data (list of lists): each list is a sentence of the text\n","    vocab (dictionary): {word: no of times it appears in the text}\n","    mincount(int): the minimum count\n","\n","    Returns:\n","    data_with_unk(list of lists): data after replacing rare words with <unk> token\n","    '''\n","    # replace words in data that are not in the vocab\n","    # or have a count that is below mincount\n","    data_with_unk = []\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    for i, sentence in enumerate(data):\n","      data_with_unk.append(sentence)\n","\n","      for j, text in enumerate(sentence):\n","\n","        if vocab.get(text, 0) < mincount :\n","          data_with_unk[i][j] = '<unk>'\n","\n","    return data_with_unk\n","\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"iEB_VcVj76QF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e6529aa-392d-45a3-a11e-6a7411f6fba7","executionInfo":{"status":"ok","timestamp":1719773503156,"user_tz":0,"elapsed":1,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["remove rare words\n","['<s>', 'my', '<unk>', \"don't\", 'speak', '<unk>', '</s>']\n"]}],"source":["print(\"remove rare words\")\n","\n","train_data = remove_rare_words(train_data, vocab, mincount = 2)\n","valid_data = remove_rare_words(valid_data, vocab, mincount = 1)\n","#train_data\n","print(train_data[0])"]},{"cell_type":"code","source":["def build_ngram(data, n):\n","    '''\n","    Parameters:\n","    data (list of lists): each list is a sentence of the text\n","    n (int): size of the n-gram\n","\n","    Returns:\n","    prob (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","    '''\n","    total_number_words = 0\n","    counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n","    def _build_ngram(data,n):\n","      counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n","      for sentence in data:\n","          sentence = tuple(sentence)\n","          ##########################################################################\n","          #                      TODO: Implement this function                     #\n","          # dict can be indexed by tuples\n","          # store in the same dict all the ngrams\n","          # by using the context as a key and the word as a value\n","          ##########################################################################\n","          # Replace \"pass\" statement with your code\n","          sentence = tuple(sentence)\n","          for i in range(len(sentence) - n + 1):\n","              context = sentence[i:i+n-1]\n","              word = sentence[i+n-1]\n","              counts[context][word] += 1\n","          ##########################################################################\n","          #                            END OF YOUR CODE                            #\n","          ##########################################################################\n","\n","      prob = defaultdict(lambda: defaultdict(lambda: 0.0))\n","      # Build the probabilities from the counts\n","      # Be careful with how you normalize!\n","\n","      for context in counts.keys():\n","        # p(w | context) = count(context, w)/ count(context)\n","        ##########################################################################\n","        #                      TODO: Implement this function                     #\n","        ##########################################################################\n","        # Replace \"pass\" statement with your code\n","        context_size = float(sum(counts[context].values()))\n","        for word in counts[context].keys():\n","            prob[context][word] = counts[context][word] / context_size\n","\n","\n","        ##########################################################################\n","        #                            END OF YOUR CODE                            #\n","        ##########################################################################\n","\n","      return prob\n","\n","    prob = defaultdict(lambda: defaultdict(lambda: 0.0)) # Replace \"...\" statement with your code\n","    for i in range(1,n+1):\n","      n_gram_prob = _build_ngram(data, i) # Replace \"...\" statement with your code\n","      for context in n_gram_prob.keys():\n","            for word in n_gram_prob[context].keys():\n","                prob[context][word] = n_gram_prob[context][word]\n","\n","    return prob\n"],"metadata":{"id":"2nqgDauAqJdM","executionInfo":{"status":"ok","timestamp":1719773503156,"user_tz":0,"elapsed":1,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","execution_count":22,"metadata":{"id":"WMxK-Qki76QG","colab":{"base_uri":"https://localhost:8080/"},"outputId":"242aade6-eb94-4902-c268-672cc038e51c","executionInfo":{"status":"ok","timestamp":1719773506950,"user_tz":0,"elapsed":3795,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["build ngram model with n =  10\n"]}],"source":["# RUN TO BUILD NGRAM MODEL\n","n = 10\n","print(\"build ngram model with n = \", n)\n","model = build_ngram(train_data, n)\n"]},{"cell_type":"markdown","metadata":{"id":"KbCzRXJk76QG"},"source":["Here, implement a recursive function over shorter and shorter context to compute a \"stupid backoff model\". An interpolation model can also be implemented this way."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"AbOs6Duc76QG","executionInfo":{"status":"ok","timestamp":1719773506950,"user_tz":0,"elapsed":5,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def get_prob(model, context, w):\n","    '''\n","    Parameters:\n","    model (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","    context (list of strings): a sentence\n","    w(string): the word we need to find it's probability given the context\n","\n","    Retunrs:\n","    prob(float): probability of this word given the context\n","    '''\n","\n","    # code a recursive function over\n","    # smaller and smaller context\n","    # to compute the backoff model\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    if len(context) == 0:\n","        return model.get((), {}).get(w, 0)\n","\n","    context = tuple(context)\n","\n","    if context in model and w in model[context]:\n","        return model[context][w]\n","\n","    else:\n","        return 0.4 * get_prob(model, context[1:], w) # The probability should be reduice to reflect the increased uncertainty.\n","\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"z5waVP3C76QH","executionInfo":{"status":"ok","timestamp":1719773506950,"user_tz":0,"elapsed":4,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def perplexity(model, data, n):\n","    '''\n","    Parameters:\n","    model (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","    data (list of lists): each list is a sentence of the text\n","    n(int): size of the n-gram\n","\n","    Retunrs:\n","    perp(float): the perplexity of the model\n","    '''\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    log_prob_sum = 0.0\n","    total_number_words = 0\n","    for sentence in data:\n","        sentence = [\"<s>\"] * (n-1) + sentence + [\"</s>\"]\n","        for i in range(n-1, len(sentence)):\n","            context = sentence[i-n+1:i]\n","            word = sentence[i]\n","            prob = get_prob(model, context, word)\n","            log_prob_sum += -np.log(prob + 1e-12)  # Avoid log(0)\n","            total_number_words += 1\n","\n","    perp = np.exp(log_prob_sum / total_number_words)\n","    return perp\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"AYBc5Aam76QH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"55d62322-67c8-4cdd-930f-55eec783e130","executionInfo":{"status":"ok","timestamp":1719773506950,"user_tz":0,"elapsed":4,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["The perplexity is 59529.29408405336\n"]}],"source":["# COMPUTE PERPLEXITY ON VALIDATION SET\n","\n","print(\"The perplexity is\", perplexity(model, valid_data, n=n))"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"idrxoRlc76QH","executionInfo":{"status":"ok","timestamp":1719773506950,"user_tz":0,"elapsed":3,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def get_proba_distrib(model, context):\n","    ## need to get the the words after the context and their probability of appearance\n","    ## after this context\n","    '''\n","    Parameters:\n","    model (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","    context (list of strings): the sentence we need to find the words after it and\n","    thier probabilites\n","\n","    Retunrs:\n","    words_and_probs(dic): {word: probability of word given context}\n","\n","    '''\n","    # code a recursive function over context\n","    # to find the longest available ngram\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    context = tuple(context)\n","    if context in model:\n","        return model[context]\n","\n","    elif len(context) > 1:\n","        return get_proba_distrib(model, context[1:])\n","\n","    else:\n","        return {}\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"i_eGYoZB76QI","executionInfo":{"status":"ok","timestamp":1719773506950,"user_tz":0,"elapsed":3,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def generate(model):\n","    '''\n","    Parameters:\n","    model (dictionary of dictionary)\n","    {\n","        context: {word:probability of this word given context}\n","    }\n","\n","    Retunrs:\n","    sentence (list of strings): a sentence sampled according to the language model.\n","\n","\n","    '''\n","    # generate a sentence. A sentence starts with a <s> and ends with a </s>\n","    # Possiblly a use function is:\n","    # np.random.choice(x, 1, p = y)\n","\n","    # where x is a list of things to sample from\n","    # and y is a list of probability (of the same length as x)\n","    sentence = [\"<s>\"]\n","    n =10\n","    #print (model[(\"<s>\")])\n","    #print (len(model[tuple(sentence)].values()))\n","    while sentence[-1] != \"</s>\" and len(sentence)<10:\n","        ##########################################################################\n","        #                      TODO: Implement this function                     #\n","        ##########################################################################\n","        # Replace \"pass\" statement with your code\n","\n","        context = sentence[-(n-1):]\n","        proba_distrib = get_proba_distrib(model, context)\n","        words = list(proba_distrib.keys())\n","        probabilities = list(proba_distrib.values())\n","        if not words:\n","            break\n","        next_word = np.random.choice(words, 1, p=probabilities)[0]\n","        sentence.append(next_word)\n","\n","    return sentence\n","        ##########################################################################\n","        #                            END OF YOUR CODE                            #\n","        ##########################################################################"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"mWqzUXjw76QI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"43b8412c-4590-4712-8f03-ba40936b431b","executionInfo":{"status":"ok","timestamp":1719773582820,"user_tz":0,"elapsed":319,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Generated sentence:  ['<s>', 'try', 'to', 'lose', 'heart', '!', '</s>']\n"]}],"source":["# GENERATE A SENTENCE FROM THE MODEL\n","\n","print(\"Generated sentence: \",generate(model))"]},{"cell_type":"markdown","metadata":{"id":"XCs2pG6P76QJ"},"source":["Once you are done implementing the model, evaluation and generation code, you can try changing the value of `n`, and play with a larger training set (`train2.txt` and `valid2.txt`). You can also try to implement an interpolation model."]},{"cell_type":"code","execution_count":29,"metadata":{"id":"INh4pNmm76QJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"41910abd-048c-4b55-9311-7e015faa312b","executionInfo":{"status":"ok","timestamp":1719773508696,"user_tz":0,"elapsed":1748,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["load training set 2..\n","\n","\n","['<s>', 'i', 'liked', 'your', 'idea', 'and', 'adopted', 'it', '.', '</s>']\n","\n","\n","how : 3195\n","load validation set 2\n"]}],"source":["print(\"load training set 2..\")\n","print(\"\\n\")\n","train_data2, vocab = load_data(\"drive/MyDrive/NLP_Week1_PS/Lab3/train2.txt\")\n","print(train_data2[0])\n","print(\"\\n\")\n","print(\"how :\",vocab['how'])\n","print(\"load validation set 2\")\n","valid_data2, _ = load_data(\"drive/MyDrive/NLP_Week1_PS/Lab3/valid2.txt\")\n"]},{"cell_type":"code","source":["n = 3"],"metadata":{"id":"xyEO8rKZB6SR","executionInfo":{"status":"ok","timestamp":1719773508696,"user_tz":0,"elapsed":1,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["model = build_ngram(train_data2, n)"],"metadata":{"id":"tq71nPJjBZRR","executionInfo":{"status":"ok","timestamp":1719773518243,"user_tz":0,"elapsed":9548,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["perplexity(model,valid_data2, n)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHcKA9nxBpXk","outputId":"9e028cdb-5364-4a1c-bed8-8c039c858fc5","executionInfo":{"status":"ok","timestamp":1719773519258,"user_tz":0,"elapsed":1024,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43.51208067993573"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["generate(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7vh3LzcBvHj","outputId":"2b823f35-d2d3-4461-927c-1ac34d3a1ddf","executionInfo":{"status":"ok","timestamp":1719773519258,"user_tz":0,"elapsed":4,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['<s>', 'judy', 'was', 'born', 'at', 'seven', 'this', 'evening', '?', '</s>']"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":[],"metadata":{"id":"4f-xb6wBB3tn","executionInfo":{"status":"ok","timestamp":1719773519258,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"execution_count":33,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2+"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}