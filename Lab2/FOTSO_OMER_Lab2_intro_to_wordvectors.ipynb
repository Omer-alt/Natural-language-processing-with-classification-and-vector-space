{"cells":[{"cell_type":"markdown","metadata":{"id":"0Rgs1M4rqlrD"},"source":["\n","<h1 style=\"font-family:verdana;font-size:300%;text-align:center;background-color:#f2f2f2;color:#0d0d0d\">MMI_2024_NLP - Week 1</h1>\n","\n","<h1 style=\"font-family:verdana;font-size:180%;text-align:Center;color:#993333\"> Lab 2: Introduction to wordvectors </h1>\n","\n","\n","Before we start, please change the name of the notebook to the following format : **Firstname_LASTNAME_Lab2_intro_to_wordvectors.ipynb**\n","\n","\n","In some cells and files you will see code blocks that look like this:\n","\n","```python\n","##############################################################################\n","#                    TODO: Write the equation for a line                     #\n","##############################################################################\n","pass\n","##############################################################################\n","#                              END OF YOUR CODE                              #\n","##############################################################################\n","```\n","\n","You should replace the `pass` statement with your own code and leave the blocks intact, like this:\n","\n","```python\n","##############################################################################\n","#                    TODO: Write the equation for a line                     #\n","##############################################################################\n","y = m * x + b\n","##############################################################################\n","#                              END OF YOUR CODE                              #\n","##############################################################################\n","```"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"YOGqnZgdqlrG","executionInfo":{"status":"ok","timestamp":1719773643837,"user_tz":0,"elapsed":3,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["import io, sys\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCayPFWFvP0j","outputId":"d3a98ab7-9dc8-4ea8-ffae-47190dd17a7b","executionInfo":{"status":"ok","timestamp":1719773663234,"user_tz":0,"elapsed":19399,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KYNmfcLwqlrG","executionInfo":{"status":"ok","timestamp":1719773673770,"user_tz":0,"elapsed":302,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["\n","def load_vectors(filename):\n","    fin = io.open(filename, 'r', encoding='utf-8', newline='\\n')\n","    n, d = map(int, fin.readline().split())\n","    data = {}\n","    for line in fin:\n","        tokens = line.rstrip().split(' ')\n","        data[tokens[0]] = np.asarray([float(x) for x in tokens[1:]])\n","    return data"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"BwcnbIq-qlrH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d855406c-60b1-4825-dd71-fd627dafa19c","executionInfo":{"status":"ok","timestamp":1719773676934,"user_tz":0,"elapsed":2816,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n"," ** Word vectors ** \n","\n","<class 'numpy.ndarray'> 300\n"]}],"source":["# Loading word vectors\n","\n","print('')\n","print(' ** Word vectors ** ')\n","print('')\n","\n","'''\n","word_vectors is a dictionary that maps words to their numerical word vector\n","[word (string)] = [np-array]\n","'''\n","# word_vectors = load_vectors('drive/MyDrive/wiki.en.vec')\n","word_vectors = load_vectors('drive/MyDrive/NLP_Week1_PS/Lab2/wiki.en.vec')\n","\n","tree_vector = word_vectors['tree']\n","print(type(tree_vector), len(tree_vector))"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"efLgsKdFqlrH","executionInfo":{"status":"ok","timestamp":1719773678321,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["## This function computes the cosine similarity between vectors u and v\n","\n","def cosine(u, v):\n","    '''\n","    Parameters:\n","    u : 1-D numpy array\n","    v : 1-D numpy array\n","\n","    Returns:\n","    cos (float) : value of the cosine similairy between vectors u, v\n","    '''\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    cos = np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n","\n","    return cos\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"11Od4NFeqlrH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c680429-21a4-4921-c809-10afab5a5ec1","executionInfo":{"status":"ok","timestamp":1719773679473,"user_tz":0,"elapsed":3,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["test similarity 1.0\n","similarity(apple, apples) = 0.637\n","similarity(apple, banana) = 0.431\n","similarity(apple, tiger) = 0.212\n"]}],"source":["# compute similarity between words\n","print (f\"test similarity {cosine(np.array([1,0,0]),np.array([1,0,0]))}\", )\n","print('similarity(apple, apples) = %.3f' %\n","      cosine(word_vectors['apple'], word_vectors['apples']))\n","print('similarity(apple, banana) = %.3f' %\n","      cosine(word_vectors['apple'], word_vectors['banana']))\n","print('similarity(apple, tiger) = %.3f' %\n","      cosine(word_vectors['apple'], word_vectors['tiger']))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"EZ4cNIfrqlrI","executionInfo":{"status":"ok","timestamp":1719773680652,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["## Functions for nearest neighbor\n","## This function returns the word corresponding to\n","## nearest neighbor vector of x\n","## The list exclude_words can be used to exclude some\n","## words from the nearest neighbors search\n","\n","def nearest_neighbor(x, word_vectors, exclude_words=[]):\n","    '''\n","    Parameters:\n","    x (string): word to find its nearest neighbour\n","    word_vectors (Python dict): {word (string): np-array of word vector}\n","    exclude_words (list of strings): words to be excluded from the search\n","\n","    Returns:\n","    best_word (string) : the word whose word vector is the nearest neighbour\n","    to the word vector of x\n","    '''\n","    best_score = -1.0\n","    best_word = None\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    exclude_set = set( exclude_words )  # Convert list to set\n","\n","    # Filter words to exclude\n","    filtered_words = {word: vector for word, vector in word_vectors.items() if word not in exclude_set}\n","\n","    for word, vector in filtered_words.items():\n","\n","      score = cosine(x, vector)\n","\n","      if score > best_score:\n","        best_score = score\n","        best_word = word\n","\n","    return best_word\n","\n","\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"M2J-6s61qlrI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c28248d-7962-47f7-e264-c49c8730506a","executionInfo":{"status":"ok","timestamp":1719773682053,"user_tz":0,"elapsed":304,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","The nearest neighbor of cat is: dog\n"]}],"source":["print('')\n","print('The nearest neighbor of cat is: ' +\n","      nearest_neighbor(word_vectors['cat'], word_vectors, exclude_words = ['cat', 'cats']))"]},{"cell_type":"markdown","metadata":{"id":"yvfo4Gl_qlrI"},"source":["#### Hint (using python priorty queues with the heapq datastructure):\n","if you don't want to store all the words and scores you can use the priortiy queue and only store the best K element so far."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"AFCxLz5AqlrI","executionInfo":{"status":"ok","timestamp":1719773684341,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["## This function return the words corresponding to the\n","## K nearest neighbors of vector x.\n","## You can use the functions heappush and heappop.\n","import heapq\n","def knn(x, vectors, k):\n","    '''\n","    Parameters:\n","    x (string): word to find its nearest neighbour\n","    word_vectors (Python dict): {word (string): np-array of word vector}\n","    k (int): number of nearest neighbours to be found\n","\n","    Returns:\n","    k_nearest_neighbors (list of tuples): [(score, word), (score, word), ....]\n","    '''\n","\n","    k_nearest_neighbors = []\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    # Using a Generating Expression to Find the Key \"cat\" in our case\n","\n","    key = next((k for k, v in word_vectors.items() if np.array_equal (v, x)), None)\n","\n","    for word, vector in vectors.items():\n","        # print(vector)\n","        if word != key:\n","            score = cosine(x, vector)\n","\n","            if len(k_nearest_neighbors) < k:\n","                heapq.heappush(k_nearest_neighbors, (score, word))\n","            else:\n","                # Let's replace the smallest element if the new score is larger.\n","                heapq.heappushpop(k_nearest_neighbors, (score, word))\n","    return sorted(k_nearest_neighbors, reverse=True)\n","\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"1CvGccZEqlrJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00ab8943-ca9a-4311-b529-99df4ca2d5a3","executionInfo":{"status":"ok","timestamp":1719773685894,"user_tz":0,"elapsed":384,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","cat\n","--------------\n","cats\t0.732\n","dog\t0.638\n","pet\t0.573\n","rabbit\t0.549\n","dogs\t0.538\n"]}],"source":["knn_cat = knn(word_vectors['cat'], word_vectors, 5)\n","print('')\n","print('cat')\n","print('--------------')\n","for score, word in knn(word_vectors['cat'], word_vectors, 5):\n","    print (word + '\\t%.3f' % score)\n"]},{"cell_type":"markdown","metadata":{"id":"e9Z6u7BjqlrJ"},"source":["#### Hint:\n","To find the analogies, we find the nearest neighbour associated with the wordvector d\n","$$ d = \\frac{c}{\\Vert {c} \\Vert} + \\frac{b}{\\Vert {b} \\Vert} - \\frac{a}{\\Vert {a} \\Vert}$$\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"vd1Odd9cqlrJ","executionInfo":{"status":"ok","timestamp":1719773688342,"user_tz":0,"elapsed":314,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["## This function return the words d, such that a:b and c:d\n","## verifies the same relation\n","\n","def analogy(a, b, c, word_vectors):\n","    '''\n","    Parameters:\n","    a (string): word a\n","    b (string): word b\n","    c (string): word c\n","    word_vectors (Python dict): {word (string): np-array of word vector}\n","\n","    Returnrs:\n","    the word d (string) associated with c such that c:d is similar to a:b\n","\n","    '''\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","\n","    # Get vectors for words a, b, c from word_vectors\n","    vector_word_a = word_vectors.get(a, None)\n","    vector_word_b = word_vectors.get(b, None)\n","    vector_word_c = word_vectors.get(c, None)\n","\n","    if vector_word_a is None or vector_word_b is None or vector_word_c is None:\n","        return None\n","\n","    normalize_vector = lambda v: v if np.linalg.norm(v) == 0 else v / np.linalg.norm(v)\n","\n","    # Normalize vectors\n","    norm_a = normalize_vector(vector_word_a)\n","    norm_b = normalize_vector(vector_word_b)\n","    norm_c = normalize_vector(vector_word_c)\n","\n","    # Calculate vector d\n","    vector_word_d = norm_c + norm_b - norm_a\n","\n","    # Find nearest neighbor to vector d\n","    d = nearest_neighbor(vector_word_d, word_vectors, exclude_words=[a, b, c])\n","\n","    return d\n","\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"3kx561vWqlrJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9fc6adca-cd36-4a59-8504-da1bdefa9d25","executionInfo":{"status":"ok","timestamp":1719773689543,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","france - paris + rome = italy\n"]}],"source":["# Word analogies\n","print('')\n","print('france - paris + rome = ' + analogy('paris', 'france', 'rome', word_vectors))"]},{"cell_type":"markdown","metadata":{"id":"nWgBv-DYqlrJ"},"source":["## A word about biases in word vectors"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"rIJWZIKPqlrJ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ad0d4eb7-2ef5-4c37-ec84-252c532b3dba","executionInfo":{"status":"ok","timestamp":1719773692120,"user_tz":0,"elapsed":288,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","similarity(genius, man) = 0.445\n","similarity(genius, woman) = 0.325\n"]}],"source":["## A word about biases in word vectors:\n","print('')\n","print('similarity(genius, man) = %.3f' %\n","      cosine(word_vectors['man'], word_vectors['genius']))\n","print('similarity(genius, woman) = %.3f' %\n","      cosine(word_vectors['woman'], word_vectors['genius']))"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"D08bHSR-qlrK","executionInfo":{"status":"ok","timestamp":1719773693860,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["## Compute the association strength between:\n","##   - a word w\n","##   - two sets of attributes A and B\n","\n","def association_strength(w, A, B, vectors):\n","    '''\n","    Parameters:\n","    w (string): word w\n","    A (list of strings): The words belonging to set A\n","    B (list of strings): The words belonging to set B\n","    vectors (Python dict): {word (string): np-array of word vector}\n","\n","    Returnrs:\n","    strength (float): the value of the association strength\n","    '''\n","    strength = 0.0\n","    part_a = 0.0\n","    part_b = 0.0\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    # Similarity of w with words in A\n","    for a in A:\n","        part_a += cosine(vectors[w], vectors[a])\n","    mean_a = part_a / len(A)\n","\n","    # Similarity of w with words in B\n","    for b in B:\n","        part_b += cosine(vectors[w], vectors[b])\n","    mean_b = part_b / len(B)\n","\n","    strength = mean_a - mean_b\n","    return strength\n","\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"pQ4wfIj_qlrK","executionInfo":{"status":"ok","timestamp":1719773694542,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["## Perform the word embedding association test between:\n","##   - two sets of words X and Y\n","##   - two sets of attributes A and B\n","\n","def weat(X, Y, A, B, vectors):\n","    '''\n","    Parameters:\n","    X (list of strings): The words belonging to set X\n","    Y (list of strings): The words belonging to set Y\n","    A (list of strings): The words belonging to set A\n","    B (list of strings): The words belonging to set B\n","    vectors (Python dict): {word (string): np-array of word vector}\n","\n","    Returns:\n","    score (float): the value of the group association strength\n","    '''\n","\n","    score = 0.0\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    score_x = 0.0\n","    score_y = 0.0\n","\n","    # Accumulates the strength of association\n","    for word_x in X:\n","        score_x += association_strength(word_x, A, B, vectors)\n","\n","    for word_y in Y:\n","        score_y += association_strength(word_y, A, B, vectors)\n","\n","    score = score_x - score_y\n","\n","    return score\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"STop3AZqqlrK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d68da2ee-1c11-4fe8-c539-43cf97a1675f","executionInfo":{"status":"ok","timestamp":1719773695249,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Word embedding association test: 0.847\n"]}],"source":["## Replicate one of the experiments from:\n","##\n","## Semantics derived automatically from language corpora contain human-like biases\n","## Caliskan, Bryson, Narayanan (2017)\n","\n","career = ['executive', 'management', 'professional', 'corporation',\n","          'salary', 'office', 'business', 'career']\n","family = ['home', 'parents', 'children', 'family',\n","          'cousins', 'marriage', 'wedding', 'relatives']\n","male = ['john', 'paul', 'mike', 'kevin', 'steve', 'greg', 'jeff', 'bill']\n","female = ['amy', 'joan', 'lisa', 'sarah', 'diana', 'kate', 'ann', 'donna']\n","\n","print('')\n","print('Word embedding association test: %.3f' %\n","      weat(career, family, male, female, word_vectors))"]},{"cell_type":"markdown","metadata":{"id":"g_3eQrt9qlrK"},"source":["## Word translation using word vectors\n","\n","In the following, we will use word vectors in English and French to translate words from English to French. The idea is to learn a linear function that maps English word vectors to their correponding French word vectors. To learn this linear mapping, we will use a small bilingual lexicon, that contains pairs of words in English and French that are translations of each other.\n","\n","The following function will load the small English-French bilingual lexicon:"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"M-FaKBoNqlrL","executionInfo":{"status":"ok","timestamp":1719773698240,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def load_lexicon(filename):\n","    '''\n","    Parameters:\n","    filename(string): the path of the lexicon\n","\n","    Returns:\n","    data(list of pairs of string): the bilingual lexicon\n","    '''\n","    fin = io.open(filename, 'r', encoding='utf-8', newline='\\n')\n","    data = []\n","    for line in fin:\n","        a, b = line.rstrip().split(' ')\n","        data.append((a, b))\n","    return data"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"Pp6K3PzJqlrL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"104d1a51-8b59-422f-c40e-34e551dbc67c","executionInfo":{"status":"ok","timestamp":1719773702998,"user_tz":0,"elapsed":4044,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["[('the', 'le'), ('the', 'les'), ('the', 'la'), ('and', 'et'), ('was', 'fut')]\n"]}],"source":["word_vectors_en = load_vectors('drive/MyDrive/NLP_Week1_PS/Lab2/wiki.en.vec')\n","word_vectors_fr = load_vectors('drive/MyDrive/NLP_Week1_PS/Lab2/wiki.fr.vec')\n","lexicon = load_lexicon(\"drive/MyDrive/NLP_Week1_PS/Lab2/lexicon-en-fr.txt\")\n","print(lexicon[:5])"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"p-yBNzQ8qlrL","executionInfo":{"status":"ok","timestamp":1719773702998,"user_tz":0,"elapsed":2,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["# We split the lexicon into a train and validation set\n","train = lexicon[:5000]\n","valid = lexicon[5000:5100]"]},{"cell_type":"markdown","metadata":{"id":"U7b1FDLHqlrL"},"source":["The following function will learn the mapping from English to French. The idea is to build two matrices $X_{\\text{en}}$ and $X_{\\text{fr}}$, and to find a mapping $M$ that minimizes $||X_{\\text{en}} W - X_{\\text{fr}} ||_2$. In numpy, this mapping can be obtained by using the `numpy.linalg.lstsq` function."]},{"cell_type":"code","execution_count":20,"metadata":{"id":"yU_BX6UvqlrL","executionInfo":{"status":"ok","timestamp":1719773710320,"user_tz":0,"elapsed":296,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def align(word_vectors_en, word_vectors_fr, lexicon):\n","    '''\n","    Parameters:\n","    word_vectors_en(dict: string -> np.array): English word vectors\n","    word_vectors_en(dict: string -> np.array): French word vectors\n","    lexicon(list of pairs of string): bilingual training lexicon\n","\n","    Returns\n","    mapping(np.array): the mapping from English to French vectors\n","    '''\n","    x_en, x_fr = [], []\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","\n","    # We create two matrices, one for the English vectors and one for the French vectors\n","    for word_en, word_fr in lexicon:\n","        if word_en in word_vectors_en and word_fr in word_vectors_fr:\n","            x_en.append(word_vectors_en[word_en])\n","            x_fr.append(word_vectors_fr[word_fr])\n","\n","    # We convert lists into numpy arrays\n","    x_en = np.array(x_en)\n","    x_fr = np.array(x_fr)\n","\n","    mapping, _, _, _ = np.linalg.lstsq(x_en, x_fr, rcond=None)\n","    return mapping\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"CbEe1oX1qlrL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f44d5b35-acbc-4d0c-d1ad-ac3b8b3f558b","collapsed":true,"executionInfo":{"status":"ok","timestamp":1719773711417,"user_tz":0,"elapsed":269,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[-0.06183285, -0.01071552,  0.00175985, ..., -0.01107046,\n","         0.01629405, -0.01644996],\n","       [-0.01655313, -0.02930488,  0.09810107, ..., -0.01744702,\n","        -0.02848298,  0.02070179],\n","       [-0.01970861, -0.0147154 ,  0.01231819, ...,  0.03036093,\n","        -0.00209909, -0.00944313],\n","       ...,\n","       [ 0.0669847 ,  0.02351181,  0.02041902, ...,  0.00886501,\n","         0.08635366,  0.00595836],\n","       [ 0.01936122,  0.00552446,  0.01234669, ..., -0.00623332,\n","        -0.05116348,  0.05634361],\n","       [ 0.00530333, -0.03424679, -0.03369923, ..., -0.01344391,\n","        -0.00051053, -0.00491391]])"]},"metadata":{},"execution_count":21}],"source":["mapping = align(word_vectors_en, word_vectors_fr, lexicon)\n","mapping"]},{"cell_type":"markdown","metadata":{"id":"YnHaso-EqlrM"},"source":["Given a mapping, a set of word English word vector and French word vectors, the next function will translate the English word to French. To do so, we apply the mapping on the English word, and retrieve the nearest neighbor of the obtained vector in the set of French word vectors. The translation is then the corresponding French word."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"muQ3jbSuqlrM","executionInfo":{"status":"ok","timestamp":1719773713905,"user_tz":0,"elapsed":287,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def translate(word, word_vectors_en, word_vectors_fr, mapping):\n","    '''\n","    Parameters:\n","    word(string): an English word\n","    word_vectors_en(dict: string -> np.array): English word vectors\n","    word_vectors_en(dict: string -> np.array): French word vectors\n","    mapping(np.array): the mapping from English to French vectors\n","\n","    Returns\n","    A string containing the translation of the English word\n","    '''\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","\n","    try:\n","        # Retrieve the English word vector\n","        vector_en = word_vectors_en[word]\n","\n","        # Apply the mapping\n","        vector_fr_pred = np.dot(vector_en, mapping)\n","\n","        # Find the nearest neighbor in the French word vectors\n","        max_score = -1.0\n","        best_word = None\n","\n","        for word_fr, vector_word_fr in word_vectors_fr.items():\n","\n","            score = cosine(vector_fr_pred, vector_word_fr)\n","            if score > max_score:\n","                max_score = score\n","                best_word = word_fr\n","\n","        return best_word\n","\n","    except KeyError:\n","\n","        print(f\"Word '{word}' not found in the English word vectors.\")\n","        return None\n","\n","\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"RfHbsKtUqlrM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1418835a-f204-42ff-fe58-b70a907b7a25","executionInfo":{"status":"ok","timestamp":1719773715146,"user_tz":0,"elapsed":413,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["homme\n","machine\n","apprentissage\n"]}],"source":["print(translate(\"man\", word_vectors_en, word_vectors_fr, mapping))\n","print(translate(\"machine\", word_vectors_en, word_vectors_fr, mapping))\n","print(translate(\"learning\", word_vectors_en, word_vectors_fr, mapping))"]},{"cell_type":"markdown","metadata":{"id":"oVz2ZMYrqlrM"},"source":["Finally, let's implement a function to evaluate this method on the validation lexicon:"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"H2ZOJKEfqlrM","executionInfo":{"status":"ok","timestamp":1719773717576,"user_tz":0,"elapsed":273,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[],"source":["def evaluate(valid, word_vectors_en, word_vectors_fr, mapping):\n","    '''\n","    Parameters:\n","    valid(a list of pairs of string): the validation lexicon\n","    word_vectors_en(dict: string -> np.array): English word vectors\n","    word_vectors_en(dict: string -> np.array): French word vectors\n","    mapping(np.array): the mapping from English to French vectors\n","\n","    Returns\n","    Accuracy(float): the accuracy on the validation lexicon\n","    '''\n","    acc, n = 0.0, 0\n","    ##########################################################################\n","    #                      TODO: Implement this function                     #\n","    ##########################################################################\n","    # Replace \"pass\" statement with your code\n","    for word_en, word_fr in valid:\n","        translated_word = translate( word_en, word_vectors_en, word_vectors_fr, mapping )\n","        if translated_word is not None:\n","            n += 1\n","            if translated_word == word_fr:\n","                acc += 1\n","\n","    return acc / n if n > 0 else 0.0\n","    ##########################################################################\n","    #                            END OF YOUR CODE                            #\n","    ##########################################################################"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"Q1tkJZYaqlrM","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f8e25b4-2165-4f44-c1ae-b876bcdd754a","executionInfo":{"status":"ok","timestamp":1719773736542,"user_tz":0,"elapsed":17855,"user":{"displayName":"Omer Elyse Fotso Wafo","userId":"11962506378386844738"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.64"]},"metadata":{},"execution_count":25}],"source":["evaluate(valid, word_vectors_en, word_vectors_fr, mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rf4O3HEMqlrM"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2+"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}